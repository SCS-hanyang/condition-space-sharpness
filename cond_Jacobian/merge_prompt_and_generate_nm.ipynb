{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "e28e2469",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Reading 3001 lines from prompts/SD1_final.csv...\n",
                        "Successfully saved 3000 unique prompts to prompts/SD1_final.txt.\n"
                    ]
                }
            ],
            "source": [
                "import csv\n",
                "import os\n",
                "\n",
                "input_path = 'prompts/SD1_final.csv'\n",
                "output_path = 'prompts/SD1_final.txt'\n",
                "\n",
                "prompts = []\n",
                "\n",
                "if os.path.exists(input_path):\n",
                "    with open(input_path, 'r', encoding='utf-8') as f:\n",
                "        lines = f.readlines()\n",
                "\n",
                "    print(f\"Reading {len(lines)} lines from {input_path}...\")\n",
                "\n",
                "    for line in lines:\n",
                "        line = line.strip()\n",
                "        if not line:\n",
                "            continue\n",
                "        \n",
                "        # Skip header if present\n",
                "        if line.startswith(',prompt,urls') or line.startswith('id,prompt,urls'):\n",
                "            continue\n",
                "\n",
                "        # Attempt to parse as CSV row\n",
                "        # Original format: index, prompt, urls\n",
                "        # We check if it parses into at least 3 columns and the last one looks like a list\n",
                "        is_csv_row = False\n",
                "        try:\n",
                "            reader = csv.reader([line], quotechar='\"')\n",
                "            row = next(reader)\n",
                "            if len(row) >= 3 and row[-1].strip().startswith('[') and row[-1].strip().endswith(']'):\n",
                "                # Likely the original CSV format -> Extract second column (prompt)\n",
                "                prompts.append(row[1])\n",
                "                is_csv_row = True\n",
                "        except:\n",
                "            pass\n",
                "        \n",
                "        if not is_csv_row:\n",
                "            # Treat as raw text line (from previous appends or non-csv format)\n",
                "            prompts.append(line)\n",
                "else:\n",
                "    print(f\"Error: {input_path} does not exist.\")\n",
                "\n",
                "# Deduplicate while preserving order\n",
                "unique_prompts = []\n",
                "seen = set()\n",
                "for p in prompts:\n",
                "    if p not in seen:\n",
                "        unique_prompts.append(p)\n",
                "        seen.add(p)\n",
                "\n",
                "# Save to SD1_final.txt\n",
                "with open(output_path, 'w', encoding='utf-8') as f:\n",
                "    for p in unique_prompts:\n",
                "        f.write(p + '\\n')\n",
                "\n",
                "print(f\"Successfully saved {len(unique_prompts)} unique prompts to {output_path}.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "7ce3a7ab",
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "partially initialized module 'datasets' has no attribute 'utils' (most likely due to a circular import)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_random_prompts\u001b[39m(count=\u001b[32m500\u001b[39m):\n\u001b[32m     15\u001b[39m     adjectives = [\u001b[33m\"\u001b[39m\u001b[33mbeautiful\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdark\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcolorful\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mabstract\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvintage\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfuturistic\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mserene\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mchaotic\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbright\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mminimalist\u001b[39m\u001b[33m\"\u001b[39m]\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/home/gpuadmin/cssin/cond_Jacobian/.venv/lib/python3.12/site-packages/datasets/__init__.py:31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfingerprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m disable_caching, enable_caching, is_caching_enabled, set_caching_enabled\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo, MetricInfo\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     32\u001b[39m     get_dataset_config_info,\n\u001b[32m     33\u001b[39m     get_dataset_config_names,\n\u001b[32m     34\u001b[39m     get_dataset_infos,\n\u001b[32m     35\u001b[39m     get_dataset_split_names,\n\u001b[32m     36\u001b[39m     inspect_dataset,\n\u001b[32m     37\u001b[39m     inspect_metric,\n\u001b[32m     38\u001b[39m     list_datasets,\n\u001b[32m     39\u001b[39m     list_metrics,\n\u001b[32m     40\u001b[39m )\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01miterable_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterableDataset\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset, load_dataset_builder, load_from_disk, load_metric\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/home/gpuadmin/cssin/cond_Jacobian/.venv/lib/python3.12/site-packages/datasets/inspect.py:31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownload\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstreaming_download_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StreamingDownloadManager\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     32\u001b[39m     dataset_module_factory,\n\u001b[32m     33\u001b[39m     get_dataset_builder_class,\n\u001b[32m     34\u001b[39m     import_main_class,\n\u001b[32m     35\u001b[39m     load_dataset_builder,\n\u001b[32m     36\u001b[39m     metric_module_factory,\n\u001b[32m     37\u001b[39m )\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeprecation_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m relative_to_absolute_path\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/home/gpuadmin/cssin/cond_Jacobian/.venv/lib/python3.12/site-packages/datasets/load.py:58\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Metric\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnaming\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m camelcase_to_snakecase, snakecase_to_camelcase\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpackaged_modules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     59\u001b[39m     _EXTENSION_TO_MODULE,\n\u001b[32m     60\u001b[39m     _MODULE_SUPPORTS_METADATA,\n\u001b[32m     61\u001b[39m     _MODULE_TO_EXTENSIONS,\n\u001b[32m     62\u001b[39m     _PACKAGED_DATASETS_MODULES,\n\u001b[32m     63\u001b[39m     _hash_python_lines,\n\u001b[32m     64\u001b[39m )\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msplits\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Split\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeprecation_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/home/gpuadmin/cssin/cond_Jacobian/.venv/lib/python3.12/site-packages/datasets/packaged_modules/__init__.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhashlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sha256\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m arrow\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudiofolder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audiofolder\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcsv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csv\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/home/gpuadmin/cssin/cond_Jacobian/.venv/lib/python3.12/site-packages/datasets/packaged_modules/arrow/arrow.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m table_cast\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m logger = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m.logging.get_logger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mArrowConfig\u001b[39;00m(datasets.BuilderConfig):\n\u001b[32m     16\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"BuilderConfig for Arrow.\"\"\"\u001b[39;00m\n",
                        "\u001b[31mAttributeError\u001b[39m: partially initialized module 'datasets' has no attribute 'utils' (most likely due to a circular import)"
                    ]
                }
            ],
            "source": [
                "# Install datasets if not present: !pip install datasets\n",
                "import random\n",
                "import pyarrow\n",
                "\n",
                "# Monkey patch for pyarrow compatibility (PyExtensionType removed in newer pyarrow)\n",
                "if not hasattr(pyarrow, 'PyExtensionType'):\n",
                "    try:\n",
                "        pyarrow.PyExtensionType = pyarrow.ExtensionType\n",
                "    except AttributeError:\n",
                "        pass\n",
                "\n",
                "from datasets import load_dataset\n",
                "\n",
                "def generate_random_prompts(count=500):\n",
                "    adjectives = [\"beautiful\", \"dark\", \"colorful\", \"abstract\", \"vintage\", \"futuristic\", \"serene\", \"chaotic\", \"bright\", \"minimalist\"]\n",
                "    subjects = [\"cat\", \"dog\", \"landscape\", \"cityscape\", \"portrait\", \"flower\", \"robot\", \"ocean\", \"mountain\", \"forest\"]\n",
                "    verbs = [\"running\", \"sleeping\", \"flying\", \"standing\", \"sitting\", \"fighting\", \"dancing\", \"glowing\", \"falling\", \"rising\"]\n",
                "    styles = [\"oil painting\", \"digital art\", \"sketch\", \"photography\", \"watercolor\", \"cyberpunk\", \"steampunk\", \"surrealism\", \"impressionism\", \"concept art\"]\n",
                "    \n",
                "    gen_prompts = []\n",
                "    for _ in range(count):\n",
                "        adj = random.choice(adjectives)\n",
                "        sub = random.choice(subjects)\n",
                "        verb = random.choice(verbs)\n",
                "        style = random.choice(styles)\n",
                "        prompt = f\"{adj} {sub} {verb} in {style} style\"\n",
                "        gen_prompts.append(prompt)\n",
                "    return gen_prompts\n",
                "\n",
                "def get_coco_captions(count=1000):\n",
                "    # Use a parquet-based COCO dataset for better streaming support\n",
                "    print(\"Streaming COCO captions...\")\n",
                "    try:\n",
                "        # merve/coco2017 is widely used and usually parquet-friendly\n",
                "        dataset = load_dataset(\"merve/coco2017\", split=\"train\", streaming=True)\n",
                "        captions = []\n",
                "        for item in dataset:\n",
                "            if 'caption' in item:\n",
                "                captions.append(item['caption'])\n",
                "            elif 'text' in item:\n",
                "                 captions.append(item['text'])\n",
                "            \n",
                "            if len(captions) >= count:\n",
                "                break\n",
                "        return captions[:count]\n",
                "    except Exception as e:\n",
                "        print(f\"Error loading COCO (merve/coco2017): {e}. Falling back to generation.\")\n",
                "        return generate_random_prompts(count)\n",
                "\n",
                "def get_laion_captions(count=1000):\n",
                "    # Use a high-quality subset of LAION which is Parquet-based\n",
                "    print(\"Streaming LAION captions...\")\n",
                "    try:\n",
                "        dataset = load_dataset(\"ChristophSchuhmann/improved_aesthetics_6.5plus\", split=\"train\", streaming=True)\n",
                "        captions = []\n",
                "        for item in dataset:\n",
                "            if 'TEXT' in item:\n",
                "                captions.append(item['TEXT'])\n",
                "            elif 'caption' in item:\n",
                "                captions.append(item['caption'])\n",
                "            \n",
                "            if len(captions) >= count:\n",
                "                break\n",
                "        return captions[:count]\n",
                "    except Exception as e:\n",
                "        print(f\"Error loading LAION: {e}. Falling back to generation.\")\n",
                "        return generate_random_prompts(count)\n",
                "\n",
                "# Main execution\n",
                "new_nm_prompts = []\n",
                "\n",
                "# 1. COCO\n",
                "coco_p = get_coco_captions(1000)\n",
                "print(f\"Fetched {len(coco_p)} COCO prompts\")\n",
                "new_nm_prompts.extend(coco_p)\n",
                "\n",
                "# 2. LAION\n",
                "laion_p = get_laion_captions(1000)\n",
                "print(f\"Fetched {len(laion_p)} LAION prompts\")\n",
                "new_nm_prompts.extend(laion_p)\n",
                "\n",
                "# 3. Generated\n",
                "gen_p = generate_random_prompts(500)\n",
                "print(f\"Generated {len(gen_p)} synthetic prompts\")\n",
                "new_nm_prompts.extend(gen_p)\n",
                "\n",
                "# Filter duplicates against existing SD1_final.txt\n",
                "existing_path = 'prompts/SD1_final.txt'\n",
                "existing_set = set()\n",
                "if os.path.exists(existing_path):\n",
                "    with open(existing_path, 'r', encoding='utf-8') as f:\n",
                "        existing_set = set(line.strip() for line in f)\n",
                "\n",
                "final_new_prompts = []\n",
                "for p in new_nm_prompts:\n",
                "    p_clean = p.strip()\n",
                "    if p_clean and p_clean not in existing_set:\n",
                "        final_new_prompts.append(p_clean)\n",
                "        existing_set.add(p_clean) # Avoid duplicates within the new set too\n",
                "\n",
                "print(f\"\\nPrepared {len(final_new_prompts)} unique non-memorized prompts.\")\n",
                "\n",
                "# Save to prompts/sd1_nm_2500.txt\n",
                "out_nm_path = 'prompts/sd1_nm_2500.txt'\n",
                "with open(out_nm_path, 'w', encoding='utf-8') as f:\n",
                "    for p in final_new_prompts:\n",
                "        f.write(p + '\\n')\n",
                "\n",
                "print(f\"Saved to {out_nm_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a43a742e",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
