{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion 2 Image Generation Test\n",
    "\n",
    "This notebook loads `stabilityai/stable-diffusion-2`, configures the DDIM scheduler, and generates images with 500 inference steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8499f453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b53a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "# Fallback option if the above fails\n",
    "# model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "\n",
    "num_inference_steps = 50\n",
    "guidance_scale = 7.5\n",
    "\n",
    "# Define your prompts here\n",
    "prompts = [\n",
    "    \"A professional photograph of an astronaut riding a horse\",\n",
    "    \"A hyper-realistic painting of a futuristic city\",\n",
    "    \"A cute corgi dog running in a park, high resolution\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bbbb650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: stabilityai/stable-diffusion-2-1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: 404 Client Error. (Request ID: Root=1-695b7f90-44e846d90044a35f46f332ec;dd889d66-14fc-4fba-9b91-97c2581c87e0)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/api/models/stabilityai/stable-diffusion-2-1.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated..\n",
      "Will try to load from local cache.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model: Cannot find an appropriate cached snapshot folder for the specified revision on the local disk and outgoing traffic has been disabled. To enable repo look-ups and downloads online, pass 'local_files_only=False' as input.\n",
      "\n",
      "Potential Fixes:\n",
      "1. Check your internet connection.\n",
      "2. Try using 'stabilityai/stable-diffusion-2-1' instead.\n",
      "3. Ensure you have access to the repository (though it should be public).\n"
     ]
    }
   ],
   "source": [
    "# Load Model and Scheduler\n",
    "print(f\"Loading model: {model_id}...\")\n",
    "try:\n",
    "    # Load the pipeline first. This is often more robust.\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_id, \n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    "    )\n",
    "    \n",
    "    # Swap scheduler to DDIM\n",
    "    pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "    pipe = pipe.to(device)\n",
    "    print(\"Model loaded successfully. Scheduler swapped to DDIMScheduler.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"\\nPotential Fixes:\")\n",
    "    print(\"1. Check your internet connection.\")\n",
    "    print(\"2. Try using 'stabilityai/stable-diffusion-2-1' instead.\")\n",
    "    print(\"3. Ensure you have access to the repository (though it should be public).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb231ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline not loaded, skipping generation.\n"
     ]
    }
   ],
   "source": [
    "# Generation Loop\n",
    "if 'pipe' in locals():\n",
    "    images = []\n",
    "    generator = torch.Generator(device).manual_seed(42) # Fixed seed\n",
    "\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"Generating image {i+1}/{len(prompts)} for prompt: '{prompt}'\")\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            image = pipe(\n",
    "                prompt, \n",
    "                num_inference_steps=num_inference_steps, \n",
    "                guidance_scale=guidance_scale,\n",
    "                generator=generator\n",
    "            ).images[0]\n",
    "        images.append(image)\n",
    "        \n",
    "        # Optional: Save image\n",
    "        image.save(f\"sd2_generated_{i}.png\")\n",
    "\n",
    "    print(\"Generation complete.\")\n",
    "else:\n",
    "    print(\"Pipeline not loaded, skipping generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "284f1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results\n",
    "if 'images' in locals() and images:\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(20, 5))\n",
    "    if len(images) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, img, prompt in zip(axes, images, prompts):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(prompt[:30] + \"...\" if len(prompt) > 30 else prompt, fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95e678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
